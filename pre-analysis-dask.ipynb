{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing with dask\n",
    "import os, sys, re, io, pathlib\n",
    "import pandas as pd\n",
    "import hiplot as hip\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "# packages needed to use dask\n",
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import multiprocessing.popen_spawn_posix\n",
    "from distributed import Client, LocalCluster\n",
    "\n",
    "# limit memory to 1 GB\n",
    "# client = Client(n_workers=4, threads_per_worker=1, memory_limit=4e9)\n",
    "\n",
    "buffer = io.StringIO()\n",
    "mix = pd.IndexSlice\n",
    "\n",
    "# define the current path (notebooks in lab_utils)\n",
    "labutilspath = str(pathlib.Path(os.getcwd()).parents[1])\n",
    "sys.path.append(labutilspath)\n",
    "\n",
    "# import the autoscan routines\n",
    "from autoscan import autoscan\n",
    "\n",
    "pp = autoscan.basics()\n",
    "\n",
    "ftir_cols = pp.probe_settings['ftir']['col'][2:]\n",
    "tips_cols = list(itertools.chain(*[p['col'][2:] for _, p in pp.probe_settings.items()]))\n",
    "ftir_lambdas = pp.probe_settings['ftir']['lambdas']\n",
    "\n",
    "def pprint(msg, msg_title = '', msg_decorator = '#', len_decorator = 40):\n",
    "    nhead = len_decorator - len(msg_title) - 2\n",
    "    if nhead <= 0:\n",
    "        nhead = 1\n",
    "        nfoot = len(msg_title) + 4\n",
    "    else:\n",
    "        nfoot = len_decorator\n",
    "    \n",
    "    top_decorator = msg_decorator * (nhead // 2) \n",
    "    print(top_decorator + ' ' + msg_title  +  ' ' + top_decorator, \n",
    "          msg, nfoot * '#' + '\\n',\n",
    "          sep = '\\n')\n",
    "    return\n",
    "\n",
    "def dfinfo(df, header = 'info'):\n",
    "    with io.StringIO() as buffer:\n",
    "        df.info(buf = buffer)\n",
    "        pprint(buffer.getvalue(), msg_title = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(name = 'dask', n_workers = 5, threads_per_worker = 4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = '/home/urlab/sandbox/data/characterization/autoscan/autoscan.h5'\n",
    "datapath = '/sandbox/data/autoscan/'\n",
    "datafile = os.path.join(datapath, 'autoscan.h5')\n",
    "savepath = datapath\n",
    "\n",
    "# load the data\n",
    "da = dd.read_hdf(datafile, '/data', chunksize = 10000)\n",
    "dn = da.iloc[:, -1760:].copy()\n",
    "ds = da.iloc[:, :8].copy()\n",
    "desc = dd.read_hdf(datafile, '/description').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_peak_to_lambda(x):\n",
    "    if x is not np.nan:\n",
    "        out = ftir_lambdas[int(x.split('_')[1]) - 1]\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "def ftir_row_stats(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            l_mean = lambda df: df.loc[:, ftir_cols].mean(axis = 1),          \n",
    "            l_std = lambda df: df.loc[:, ftir_cols].std(axis = 1),\n",
    "            # l_median = lambda df: np.median(df.iloc[:, 2:1754], axis = 1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def rock_mechanics(df: dd.DataFrame) >> dd,DataFrame:\n",
    "    \n",
    "def clean_dataframe(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    return (\n",
    "        df\n",
    "        .where(df >= 0, np.nan)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "\n",
    "def enforce_limits(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    for k, p in pp.probe_settings.items():\n",
    "        v = p['col'][2:]\n",
    "        vmin, vmax = p['limits']\n",
    "        df[v] = df[v].where(((df[v] >= vmin) & (df[v] <= vmax)), np.nan)\n",
    "    return df\n",
    "\n",
    "def compute_final_dataframe(df: dd.DataFrame, workers = 20) -> pd.DataFrame:\n",
    "    \"\"\"Execute dask task graph and compute final results\"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .compute(num_workers = 6)\n",
    "    )\n",
    "\n",
    "def hip_visualize(df, pcols = None, index = ['family', 'code']):\n",
    "    dp = df.reset_index().loc[:, np.append(index, pcols)]\n",
    "    s = hip.Experiment.from_dataframe(dp)\n",
    "    s.colormap = 'interpolateViridis'\n",
    "    s.display()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = clean_dataframe(dn)\n",
    "dn = enforce_limits(dn)\n",
    "dn = ftir_row_stats(dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dn.compute()\n",
    "ds = ds.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max_peaks = df.loc[:, ftir_cols].idxmax(axis = 1)\n",
    "idx_min_peaks = df.loc[:, ftir_cols].idxmin(axis = 1)\n",
    "df.loc[:, 'l_max_peak'] = idx_max_peaks.apply(lambda x: idx_peak_to_lambda(x))\n",
    "df.loc[:, 'l_min_peak'] = idx_min_peaks.apply(lambda x: idx_peak_to_lambda(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = hip_visualize(df.dropna(subset = ['perm', 'vp0', 'vs0', 'e_star', 'l_max_peak']), \n",
    "#                   pcols = ['l_max_peak', 'l_min_peak', 'perm', 'vp0', 'vs0', 'e_star'], \n",
    "#                   index = ['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-justice",
   "metadata": {},
   "source": [
    "# data cleaning with klib\n",
    "1. pre-clean the dataset\n",
    " - remove duplicated rows\n",
    " - enforce correct dtypes \n",
    " - reduce memory overhead\n",
    " - do not remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import klib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the record print the information of the original dataframe\n",
    "dfinfo(df, 'raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-clean, do not remove missing values\n",
    "df = klib.data_cleaning(df, drop_threshold_rows = 1.0, clean_col_names = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_numerical = ['x', 'y'] + tips_cols + ['l_mean', 'l_std', 'l_max_peak', 'l_min_peak']\n",
    "col_categorical = ['family', 'code', 'tag', 'subtag', 'instance', 'experiment', 'side', 'm']\n",
    "df.loc[:, col_numerical] = df.loc[:, col_numerical].astype(np.float32)\n",
    "# df.loc[:, col_categorical] = df.loc[:, col_categorical].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the information of the cleaned dataframe\n",
    "dfinfo(df, 'raw data cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-money",
   "metadata": {},
   "source": [
    "## fix values and correct information\n",
    "1. set nan to measurements where all values are the same (ftir)\n",
    "2. set the correct family and code for eur samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = df.loc[:, ftir_cols].apply(lambda x: len(np.unique(x)), axis = 1) == 1\n",
    "df.loc[ix, ftir_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.tag.str.contains('eur'), 'family'] = 'shale'\n",
    "df.loc[df.tag.str.contains('eur'), 'code'] = 'sh'\n",
    "df.loc[:, col_categorical] = df.loc[:, col_categorical].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, col_numerical].to_hdf(os.path.join('/sandbox/data/', 'autoscan_corrected.h5'), key = 'data', format = 'table', mode = 'w')\n",
    "df.loc[:, col_categorical].to_hdf(os.path.join('/sandbox/data/', 'autoscan_corrected.h5'), key = 'desc', mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_ftir = df.loc[ix, :].set_index(col_categorical[:-1]).index.unique()\n",
    "pd.DataFrame.from_records(repeat_ftir.to_numpy(), columns = col_categorical[:-1]).to_csv(os.path.join(datapath, 'ftir_repeat.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-faith",
   "metadata": {},
   "source": [
    "# visualization\n",
    "1. hip-plot (again) but with corrected data\n",
    "2. distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-bread",
   "metadata": {},
   "source": [
    "## hip\n",
    "### without `e_star`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'before'\").dropna(subset = ['perm', 'vp0', 'vs0', 'l_max_peak']), \n",
    "                  pcols = ['l_max_peak', 'l_min_peak', 'perm', 'vp0', 'vs0'], \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_before_woestar.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'after'\").dropna(subset = ['perm', 'vp0', 'vs0', 'l_max_peak']), \n",
    "                  pcols = ['l_max_peak', 'l_min_peak', 'perm', 'vp0', 'vs0'], \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_before_westar.html'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-baker",
   "metadata": {},
   "source": [
    "### with `e_star`\n",
    "the number of samples with impulse hammer measurements are 1/4th of the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'before'\").dropna(subset = ['perm', 'vp0', 'vs0', 'e_star', 'l_max_peak']), \n",
    "                  pcols = ['l_max_peak', 'l_min_peak', 'perm', 'vp0', 'vs0', 'e_star'], \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_after_woestar.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'after'\").dropna(subset = ['perm', 'vp0', 'vs0', 'e_star', 'l_max_peak']), \n",
    "                  pcols = ['l_max_peak', 'l_min_peak', 'perm', 'vp0', 'vs0', 'e_star'], \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_after_westar.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'before'\").dropna(subset = ['perm', 'vp0', 'vs0']), \n",
    "                  pcols = ['perm', 'vp0', 'vs0'], \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_before_permvel.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'after'\").dropna(subset = ['perm', 'vp0', 'vs0']), \n",
    "                  pcols = ['perm', 'vp0', 'vs0'], \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_after_permvel.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = df.query(\"instance == 'before'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_perm = df_before.perm.isna() == False\n",
    "df_perm_before = df_before.loc[ix_perm, ['family', 'code', 'perm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.stripplot(y = 'perm', x = 'family', hue = 'code', data = df_perm_before, palette = 'viridis', ax = ax)\n",
    "plt.yscale('log')\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.violinplot(y = 'perm', x = 'code', hue = 'family', data = df_perm_before, palette = 'viridis', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perm_before_clipped = df_perm_before.copy()\n",
    "df_perm_before_clipped.loc[:, 'perm'] = df_perm_before_clipped.perm.clip(lower = 0, upper = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.violinplot(y = 'perm', x = 'code', hue = 'family', data = df_perm_before_clipped, palette = 'viridis', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.boxplot(y = 'perm', x = 'code', hue = 'family', data = df_perm_before_clipped, palette = 'viridis', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.kdeplot(x = 'perm',  hue = 'code', data = df_perm_before_clipped, \n",
    "            palette = 'viridis', shade = 'fill', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-indonesia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:numerics] *",
   "language": "python",
   "name": "conda-env-numerics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
