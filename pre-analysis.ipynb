{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "buffer = io.StringIO()\n",
    "\n",
    "def probeix(df, vmin, vmax):\n",
    "    return np.logical_and((df >= vmin).all(axis = 1), (df <= vmax).all(axis = 1))\n",
    "\n",
    "def test(x, th = 0.5, vmin = 0, vmax = 1e6):\n",
    "    s = probeix(x, vmin = vmin, vmax = vmax)\n",
    "    test = s.sum() / len(s) >= th\n",
    "#     ntrue  = s.sum()\n",
    "#     nfalse = (s == False).sum()\n",
    "    return test\n",
    "\n",
    "def get_wrong_measurements(df, probe = None, desc = None, th = 0.5, vmin = 0, vmax = 1e6):\n",
    "#     desc2 = desc.sort_index()\n",
    "    ix = vels.groupby(level = desc.index.names).apply(test, vmin = vmin, vmax = vmax)\n",
    "    if not np.logical_or(probe is None, desc is None):\n",
    "        out = desc.loc[ix == False].query(\"probe == '%s'\" %(probe))\n",
    "        out = (out, ix)\n",
    "    else:\n",
    "        out = ix\n",
    "    return out\n",
    "\n",
    "def pprint(msg, msg_title = '', msg_decorator = '#', len_decorator = 40):\n",
    "    nhead = len_decorator - len(msg_title) - 2\n",
    "    if nhead <= 0:\n",
    "        nhead = 1\n",
    "        nfoot = len(msg_title) + 4\n",
    "    else:\n",
    "        nfoot = len_decorator\n",
    "    \n",
    "    top_decorator = msg_decorator * (nhead // 2) \n",
    "    print(top_decorator + ' ' + msg_title  +  ' ' + top_decorator, \n",
    "          msg, nfoot * '#' + '\\n',\n",
    "          sep = '\\n')\n",
    "    return\n",
    "\n",
    "def dfinfo(df, header = 'info'):\n",
    "    with io.StringIO() as buffer:\n",
    "        df.info(buf = buffer)\n",
    "        pprint(buffer.getvalue(), msg_title = header)\n",
    "\n",
    "mix = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/urlab/sandbox/data/characterization/autoscan/autoscan.h5'\n",
    "savepath = '/home/urlab/Documents/'\n",
    "\n",
    "# load the data\n",
    "df = pd.read_hdf(datapath, key = 'data')\n",
    "desc = pd.read_hdf(datapath, key = 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "velcols = df.columns[-4:-2]\n",
    "permcol = 'perm'\n",
    "hammcol = 'e_star'\n",
    "\n",
    "describe_cols = ['mean', 'std', 'min', 'max',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# info of raw #############\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 79774 entries, ('carbonate', 'ah', 'ah_001', 's0', 'after', 4, 0) to ('sandstone', 'sg', 'wsg_006', 'plugs', 'before', 4, 3)\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   vs_0    51666 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.9+ MB\n",
      "\n",
      "########################################\n",
      "\n",
      "############### raw data ###############\n",
      "           vs_0\n",
      "count  51666.00\n",
      "mean    2530.42\n",
      "std     3641.12\n",
      "min   -89552.24\n",
      "25%     1886.74\n",
      "50%     2180.80\n",
      "75%     2699.68\n",
      "max     7526.48\n",
      "########################################\n",
      "\n",
      "######### correct measurements #########\n",
      "           vs_0\n",
      "count  51566.00\n",
      "mean    2677.26\n",
      "std     1374.35\n",
      "min      905.69\n",
      "25%     1890.67\n",
      "50%     2181.18\n",
      "75%     2700.51\n",
      "max     7526.48\n",
      "########################################\n",
      "\n",
      "###### correct + data inputation ######\n",
      "           vs_0\n",
      "count  48447.00\n",
      "mean    2715.13\n",
      "std     1395.56\n",
      "min      905.69\n",
      "25%     1942.15\n",
      "50%     2190.73\n",
      "75%     2709.69\n",
      "max     7526.48\n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set min and max expected for measurement\n",
    "velmin = 0.5e3\n",
    "velmax = 8.0e3\n",
    "\n",
    "# check velocities\n",
    "vels = df.loc[:, [velcols[1]]]\n",
    "\n",
    "## identify offending values and those to keep\n",
    "velidx = probeix(vels, vmin = velmin, vmax = velmax)\n",
    "\n",
    "dfinfo(vels, 'info of raw')\n",
    "## firtst check how they are distributed\n",
    "pprint(vels.describe().apply(np.round, decimals = 2), 'raw data')\n",
    "\n",
    "\n",
    "## check the data makes sense\n",
    "vels.loc[velidx == False, :] = np.nan\n",
    "# dfinfo(vels, 'info of corrected')\n",
    "pprint(vels.describe().apply(np.round, decimals = 2), 'correct measurements')\n",
    "\n",
    "# get the labels that have problem\n",
    "out, ix = get_wrong_measurements(vels, probe = 'vel', desc = desc, vmin = velmin, vmax = velmax)\n",
    "ixd = vels.loc[ix, :].index\n",
    "# the ix returned from `get_wrong_measurements` keeps only samples where  more than a threshold percent (`th`) of values are correct.\n",
    "# samples that don't meet this criteria are lost. This is different than probeix, which only asserts if the values are within a range independently of their sample. \n",
    "\n",
    "# ix can be used to do basic data inputation on the sample, for example by filling it with the mean\n",
    "# vels.loc[ixd] = vels.loc[ixd].groupby(level = desc.index.names).apply(lambda x: x.fillna(x.mean()))\n",
    "# ixs = vels.dropna().index\n",
    "\n",
    "# set all the samples that did not meet the criteria to nan\n",
    "# vels.loc[mix[ix == False, :]] = np.nan\n",
    "\n",
    "# dfinfo(vels.loc[mix[ix, :]], 'info of mix')\n",
    "pprint(vels.loc[ixd, :].describe().apply(np.round, decimals = 2), 'correct + data inputation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  ###################\n",
      "count    48447.000000\n",
      "mean      2715.128479\n",
      "std       1395.557082\n",
      "min        905.689672\n",
      "25%       1942.147137\n",
      "50%       2190.729043\n",
      "75%       2709.686160\n",
      "max       7526.477071\n",
      "Name: vs_0, dtype: float64\n",
      "########################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/urlab/sandbox/opt/anaconda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2877: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  result = self._run_cell(\n",
      "/home/urlab/sandbox/opt/anaconda/lib/python3.8/site-packages/IPython/core/async_helpers.py:68: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  coro.send(None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  ###################\n",
      "count    52218.000000\n",
      "mean      2692.374593\n",
      "std       1357.369170\n",
      "min        905.689672\n",
      "25%       1931.693923\n",
      "50%       2231.704026\n",
      "75%       2704.264529\n",
      "max       7526.477071\n",
      "Name: vs_0, dtype: float64\n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.loc[ixs, df.columns[:-2]]\n",
    "c = ['x', 'y'] + [vels.columns.values[0]]\n",
    "pprint(df.loc[ixd, c[-1]].describe())\n",
    "\n",
    "# this for loop should be a function to usee apply\n",
    "for g, d in df.loc[ixd, c].groupby(level = desc.index.names):    \n",
    "#     s = d.loc[d.loc[:, c[-1]].isna()].index.get_level_values(6)\n",
    "    m = d.iloc[:, -1].isna().values\n",
    "    s = d.loc[m].index.get_level_values(6)\n",
    "    if len(s) > 0:\n",
    "        x, y, v = d.values.T\n",
    "        if np.diff(s, n = len(s) - 1) != 0:\n",
    "            vu = np.repeat(v, 2).reshape((len(v), 2))\n",
    "            for k, u in enumerate([x, y]):\n",
    "                vu[m, k] = np.interp(u[m], u[m == False], v[m == False])\n",
    "            v = np.mean(vu, axis = 1)\n",
    "        else:\n",
    "            v[m] = v.mean()\n",
    "            \n",
    "        df.loc[g, c[-1]]  = v\n",
    "pprint(df.loc[ixd, c[-1]].describe())      \n",
    "# np.interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m\n",
       "0     2770.868931\n",
       "1     2722.217181\n",
       "2     2732.435967\n",
       "3     2848.210713\n",
       "4     2979.949199\n",
       "5     2971.705122\n",
       "6     3077.599472\n",
       "7     3147.269744\n",
       "8     3196.760616\n",
       "9     3247.807730\n",
       "10    3310.762342\n",
       "11    3329.026735\n",
       "12    3347.493763\n",
       "13            NaN\n",
       "14            NaN\n",
       "15            NaN\n",
       "16            NaN\n",
       "17            NaN\n",
       "18            NaN\n",
       "19            NaN\n",
       "20            NaN\n",
       "Name: vs_0, dtype: float64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.mean(vu, axis = 1)\n",
    "\n",
    "# np.interp()\n",
    "# t = df.loc[d.index, c]\n",
    "\n",
    "# s = [1, 2, 3, 4, 6, 9, 10, 13, 15, 17, 18, 21, 22, 23, 24]\n",
    "\n",
    "# np.diff(t.loc[t.iloc[:, -1].isna().any()].index.get_level_values(6), n = 2)\n",
    "# t = df.loc[d.index, ['x', 'y', 'vp_0', 'vs_0']]\n",
    "# print(t.mean())\n",
    "# t.fillna(t.mean())\n",
    "# s = vels.index.droplevel(6)\n",
    "# d = [False] * len(s)\n",
    "# for j in ix[ix].index.values:\n",
    "#     for k, v in enumerate(s.values):\n",
    "#         if v == j:\n",
    "#             d[k] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (np.diff(t.loc[t.iloc[:, -1].isna().any(axis = 1)].index.get_level_values(6), n = 2) == 0).all()\n",
    "# vu[:, 0]\n",
    "# v = velidx.index.droplevel(6).values\n",
    "# t = ix[ix.index.values\n",
    "# x = [vels.index[k] for j in range(len(t)) for k in range(len(s.values)) if v[k] == t[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  ###################\n",
      "               perm\n",
      "count  4.986200e+04\n",
      "mean   1.061643e+03\n",
      "std    4.451099e+04\n",
      "min    4.698540e-01\n",
      "25%    1.819275e+00\n",
      "50%    2.548140e+00\n",
      "75%    1.141058e+02\n",
      "max    5.307500e+06\n",
      "########################################\n",
      "\n",
      "###################  ###################\n",
      "               perm\n",
      "count  4.986200e+04\n",
      "mean   1.061643e+03\n",
      "std    4.451099e+04\n",
      "min    4.698540e-01\n",
      "25%    1.819275e+00\n",
      "50%    2.548140e+00\n",
      "75%    1.141058e+02\n",
      "max    5.307500e+06\n",
      "########################################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>probe</th>\n",
       "      <th>relroot</th>\n",
       "      <th>loaded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <th>code</th>\n",
       "      <th>tag</th>\n",
       "      <th>subtag</th>\n",
       "      <th>instance</th>\n",
       "      <th>side</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shale</th>\n",
       "      <th>sh</th>\n",
       "      <th>sh_008</th>\n",
       "      <th>s0</th>\n",
       "      <th>before</th>\n",
       "      <th>3</th>\n",
       "      <td>perm</td>\n",
       "      <td>sh_008/processed/perm_before_top.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandstone</th>\n",
       "      <th>bg</th>\n",
       "      <th>bg_009</th>\n",
       "      <th>s0</th>\n",
       "      <th>before</th>\n",
       "      <th>3</th>\n",
       "      <td>perm</td>\n",
       "      <td>bg_009/subsamples/s0/processed/perm_before_top...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbonate</th>\n",
       "      <th>ls</th>\n",
       "      <th>lssy_011</th>\n",
       "      <th>s3</th>\n",
       "      <th>before</th>\n",
       "      <th>4</th>\n",
       "      <td>perm</td>\n",
       "      <td>lssy_011/subsamples/s3/processed/perm_before_a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandstone</th>\n",
       "      <th>bg</th>\n",
       "      <th>bg_012</th>\n",
       "      <th>s0</th>\n",
       "      <th>before</th>\n",
       "      <th>7</th>\n",
       "      <td>perm</td>\n",
       "      <td>bg_012/processed/perm_before_d.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbonate</th>\n",
       "      <th>ls</th>\n",
       "      <th>lssy_011</th>\n",
       "      <th>s1</th>\n",
       "      <th>before</th>\n",
       "      <th>5</th>\n",
       "      <td>perm</td>\n",
       "      <td>lssy_011/subsamples/s1/processed/perm_before_b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sandstone</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">bg</th>\n",
       "      <th>bg_004</th>\n",
       "      <th>s2</th>\n",
       "      <th>after</th>\n",
       "      <th>4</th>\n",
       "      <td>perm</td>\n",
       "      <td>bg_004/subsamples/s2/processed/perm_after.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg_011</th>\n",
       "      <th>s0</th>\n",
       "      <th>before</th>\n",
       "      <th>6</th>\n",
       "      <td>perm</td>\n",
       "      <td>bg_011/processed/perm_before_c.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">shale</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sh</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sh_006</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">s0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">before</th>\n",
       "      <th>6</th>\n",
       "      <td>perm</td>\n",
       "      <td>sh_006/processed/perm_before_c.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perm</td>\n",
       "      <td>sh_006/processed/perm_before_b.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandstone</th>\n",
       "      <th>bg</th>\n",
       "      <th>bg_004</th>\n",
       "      <th>s1</th>\n",
       "      <th>after</th>\n",
       "      <th>4</th>\n",
       "      <td>perm</td>\n",
       "      <td>bg_004/subsamples/s1/processed/perm_after.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             probe  \\\n",
       "family    code tag      subtag instance side         \n",
       "shale     sh   sh_008   s0     before   3     perm   \n",
       "sandstone bg   bg_009   s0     before   3     perm   \n",
       "carbonate ls   lssy_011 s3     before   4     perm   \n",
       "sandstone bg   bg_012   s0     before   7     perm   \n",
       "carbonate ls   lssy_011 s1     before   5     perm   \n",
       "sandstone bg   bg_004   s2     after    4     perm   \n",
       "               bg_011   s0     before   6     perm   \n",
       "shale     sh   sh_006   s0     before   6     perm   \n",
       "                                        5     perm   \n",
       "sandstone bg   bg_004   s1     after    4     perm   \n",
       "\n",
       "                                                                                        relroot  \\\n",
       "family    code tag      subtag instance side                                                      \n",
       "shale     sh   sh_008   s0     before   3                  sh_008/processed/perm_before_top.csv   \n",
       "sandstone bg   bg_009   s0     before   3     bg_009/subsamples/s0/processed/perm_before_top...   \n",
       "carbonate ls   lssy_011 s3     before   4     lssy_011/subsamples/s3/processed/perm_before_a...   \n",
       "sandstone bg   bg_012   s0     before   7                    bg_012/processed/perm_before_d.csv   \n",
       "carbonate ls   lssy_011 s1     before   5     lssy_011/subsamples/s1/processed/perm_before_b...   \n",
       "sandstone bg   bg_004   s2     after    4         bg_004/subsamples/s2/processed/perm_after.csv   \n",
       "               bg_011   s0     before   6                    bg_011/processed/perm_before_c.csv   \n",
       "shale     sh   sh_006   s0     before   6                    sh_006/processed/perm_before_c.csv   \n",
       "                                        5                    sh_006/processed/perm_before_b.csv   \n",
       "sandstone bg   bg_004   s1     after    4         bg_004/subsamples/s1/processed/perm_after.csv   \n",
       "\n",
       "                                              loaded  \n",
       "family    code tag      subtag instance side          \n",
       "shale     sh   sh_008   s0     before   3       True  \n",
       "sandstone bg   bg_009   s0     before   3       True  \n",
       "carbonate ls   lssy_011 s3     before   4       True  \n",
       "sandstone bg   bg_012   s0     before   7       True  \n",
       "carbonate ls   lssy_011 s1     before   5       True  \n",
       "sandstone bg   bg_004   s2     after    4       True  \n",
       "               bg_011   s0     before   6       True  \n",
       "shale     sh   sh_006   s0     before   6       True  \n",
       "                                        5       True  \n",
       "sandstone bg   bg_004   s1     after    4       True  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = df.loc[:, [permcol]]\n",
    "pprint(perm.describe())\n",
    "permidx = probeix(perm, vmin = 0, vmax = np.inf)\n",
    "## check the data makes sense\n",
    "pprint(perm.loc[permidx, :].describe())\n",
    "\n",
    "## print the labels that have problem\n",
    "out, _  = get_wrong_measurements(perm, 'perm', desc)\n",
    "out.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove offending values and keep just good measurements\n",
    "idx = np.logical_and(velidx.values, permidx.values)\n",
    "dc = df.loc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative, fill the values with means or nans\n",
    "vels.loc[velidx == False, :] = np.nan\n",
    "desc.loc[vels.index[velidx == False].droplevel(6).drop_duplicates()].query(\"probe == 'vel'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = velidx[velidx == False].index.droplevel(6).drop_duplicates()\n",
    "# for t in x:\n",
    "#     vels.loc[mix[[*t], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = vels.groupby(level = velidx.index.names[:-1], sort = False).apply(np.mean)\n",
    "\n",
    "# for dd in means.index:\n",
    "#     pass\n",
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix = pd.IndexSlice\n",
    "# mix[[*ix], :]\n",
    "# vels.loc(axis = 0)[mix[[dd], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myquery(x, vels, velmin = 0.5e3, velmax = v):\n",
    "#     v = vels.copy()\n",
    "#     s = v.loc[x, :].shape[0]\n",
    "#     idx = np.logical_and((v >= velmin).all(axis = 1), (v <= velmax).all(axis = 1))\n",
    "#     skeep = np.sum(idx)\n",
    "#     sdrop = np.sum(idx == False)\n",
    "#     return s, skeep, sdrop\n",
    "\n",
    "# for a, b in idx.loc[revise_idx, :].groupby(level = idx.index.names[2:-1]):\n",
    "#     pass#.describe()\n",
    "\n",
    "# x = revise_idx.droplevel(6).drop_duplicates()\n",
    "# idx.loc[slice(x, :), :]\n",
    "\n",
    "# idx.loc[revise_idx, :]\n",
    "# idx.groupby(level = idx.index.names[2:-1]).describe()\n",
    "# .loc[:, 'r'] = 'review'\n",
    "\n",
    "# mix = pd.IndexSlice\n",
    "# pd.concat((idx.loc[mix[[*t], :]] for t in x)) \n",
    "\n",
    "# mix = pd.IndexSlice\n",
    "# pd.concat((idx.loc[mix[[*t], :]] for t in x)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
