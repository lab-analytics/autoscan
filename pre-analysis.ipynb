{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, io, pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import hiplot as hip\n",
    "import klib\n",
    "import seaborn as sns\n",
    "from dask import dataframe as dd\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "buffer = io.StringIO()\n",
    "mix = pd.IndexSlice\n",
    "\n",
    "# define the current path (notebooks in lab_utils)\n",
    "labutilspath = str(pathlib.Path(os.getcwd()).parents[1])\n",
    "sys.path.append(labutilspath)\n",
    "\n",
    "# import the autoscan routines\n",
    "from autoscan import autoscan\n",
    "\n",
    "pp = autoscan.basics()\n",
    "\n",
    "def probeix(df, vmin, vmax):\n",
    "    a = (df >= vmin)\n",
    "    b = (df <= vmax)\n",
    "    if not isinstance(df, pd.Series):\n",
    "        a = a.all(axis = 1)\n",
    "        b = b.all(axis = 1)\n",
    "    \n",
    "    return np.logical_and(a, b)\n",
    "\n",
    "def test(x, th = 0.5, vmin = 0, vmax = 1e6):\n",
    "    s = probeix(x, vmin = vmin, vmax = vmax)\n",
    "    test = s.sum() / len(s) >= th\n",
    "#     ntrue  = s.sum()\n",
    "#     nfalse = (s == False).sum()\n",
    "    return test\n",
    "\n",
    "def get_wrong_measurements(df, probe = None, desc = None, th = 0.5, vmin = 0, vmax = 1e6):\n",
    "#     desc2 = desc.sort_index()\n",
    "    if desc is None:\n",
    "        levels = df.index.names\n",
    "    else:\n",
    "        levels = desc.index.names\n",
    "    \n",
    "    ix = df.groupby(level = levels).apply(test, vmin = vmin, vmax = vmax)\n",
    "    \n",
    "    if not np.logical_or(probe is None, desc is None):\n",
    "        out = desc.loc[ix[ix == False].index].query(\"probe == '%s'\" %(probe))\n",
    "        out = (out, ix)\n",
    "    else:\n",
    "        out = ix\n",
    "    \n",
    "    return out\n",
    "\n",
    "def pprint(msg, msg_title = '', msg_decorator = '#', len_decorator = 40):\n",
    "    nhead = len_decorator - len(msg_title) - 2\n",
    "    if nhead <= 0:\n",
    "        nhead = 1\n",
    "        nfoot = len(msg_title) + 4\n",
    "    else:\n",
    "        nfoot = len_decorator\n",
    "    \n",
    "    top_decorator = msg_decorator * (nhead // 2) \n",
    "    print(top_decorator + ' ' + msg_title  +  ' ' + top_decorator, \n",
    "          msg, nfoot * '#' + '\\n',\n",
    "          sep = '\\n')\n",
    "    return\n",
    "\n",
    "def dfinfo(df, header = 'info'):\n",
    "    with io.StringIO() as buffer:\n",
    "        df.info(buf = buffer)\n",
    "        pprint(buffer.getvalue(), msg_title = header)\n",
    "\n",
    "def interp_on_nans(d, debug = False, extrap = np.mean, coords = ['x', 'y']):\n",
    "    mask = d.iloc[:, -1].isna().values == False\n",
    "    if not mask.all():\n",
    "    #     x, y, v = d.values.T\n",
    "        c = (d.iloc[:, :2] == d.iloc[0, :2]).all() == False\n",
    "        c = d.columns[np.append(c, True)]\n",
    "        mean = extrap(d.iloc[mask, -1])\n",
    "        if len(c) == 2:\n",
    "            v = np.interp(d.loc[mask == False, c[0]], d.loc[mask, c[0]], d.iloc[mask, -1], left = mean, right = mean)\n",
    "        elif len(c) == 3:\n",
    "            try:\n",
    "                v = interpolate.griddata(d.loc[mask, coords], d.iloc[mask, -1], d.loc[mask == False, coords], fill_value = mean)\n",
    "            except:\n",
    "                if debug: print('interp failed for: ', g)\n",
    "                v = mean\n",
    "        \n",
    "        d.iloc[mask == False, -1] = v\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client, LocalCluster\n",
    "# client = Client()\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster)\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    }
   ],
   "source": [
    "# datapath = '/home/urlab/sandbox/data/characterization/autoscan/autoscan.h5'\n",
    "datapath = '/sandbox/data/autoscan/autoscan.h5'\n",
    "savepath = datapath\n",
    "\n",
    "# load the data\n",
    "# try: \n",
    "#     da = dd.read_hdf(datapath, '/data')\n",
    "#     desc = dd.read_hdf(datapath, '/description').compute()\n",
    "# except: \n",
    "da = pd.read_hdf(datapath, key = 'data')\n",
    "desc = pd.read_hdf(datapath, key = 'description')\n",
    "da = dd.from_pandas(da.reset_index(drop = True), npartitions = 10)\n",
    "desc = dd.from_pandas(desc.reset_index(drop =False), npartitions = 1).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftir_row_stats(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            l_mean = lambda df: df.iloc[:, 2:1754].mean(axis = 1),          \n",
    "            l_std = lambda df: df.iloc[:, 2:1754].std(axis = 1),\n",
    "            # l_median = lambda df: np.median(df.iloc[:, 2:1754], axis = 1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def clean_dataframe(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    return (\n",
    "        df\n",
    "        .where(df >= 0, np.nan)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "\n",
    "def enforce_limits(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    for k, p in pp.probe_settings.items():\n",
    "        v = p['col'][2:]\n",
    "        vmin, vmax = p['limits']\n",
    "        df[v] = df[v].where(((df[v] >= vmin) & (df[v] <= vmax)), np.nan)\n",
    "    return df\n",
    "\n",
    "def compute_final_dataframe(df: dd.DataFrame, workers = 20) -> pd.DataFrame:\n",
    "    \"\"\"Execute dask task graph and compute final results\"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .compute(num_workers = 20)\n",
    "    )\n",
    "\n",
    "def hip_visualize(df, pcols = None, index = ['family', 'code']):\n",
    "    dp = df.reset_index().loc[:, np.append(index, pcols)]\n",
    "    s = hip.Experiment.from_dataframe(dp)\n",
    "    s.colormap = 'interpolateViridis'\n",
    "    s.display()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = clean_dataframe(da)\n",
    "db = enforce_limits(db)\n",
    "db = ftir_row_stats(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  7.3s\n",
      "CPU times: user 42.6 s, sys: 14.8 s, total: 57.5 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df = db.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Index(['family', 'code'], dtype='object'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-656ecfba565e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhip_visualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'perm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vp0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vs0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'perm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vp0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vs0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-2a15a257c9af>\u001b[0m in \u001b[0;36mhip_visualize\u001b[0;34m(df, pcols, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhip_visualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'family'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'interpolateViridis'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sandbox/opt/miniconda/envs/numerics/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1322\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                     \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Index(['family', 'code'], dtype='object'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "s = hip_visualize(df.dropna(subset = ['perm', 'vp0', 'vs0']), pcols = ['perm', 'vp0', 'vs0', 'l_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>l_1</th>\n",
       "      <th>l_2</th>\n",
       "      <th>l_3</th>\n",
       "      <th>l_4</th>\n",
       "      <th>l_5</th>\n",
       "      <th>l_6</th>\n",
       "      <th>l_7</th>\n",
       "      <th>l_8</th>\n",
       "      <th>...</th>\n",
       "      <th>l_1751</th>\n",
       "      <th>l_1752</th>\n",
       "      <th>perm</th>\n",
       "      <th>vp0</th>\n",
       "      <th>vp90</th>\n",
       "      <th>vs0</th>\n",
       "      <th>vs90</th>\n",
       "      <th>e_star</th>\n",
       "      <th>l_mean</th>\n",
       "      <th>l_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.69102</td>\n",
       "      <td>1.69771</td>\n",
       "      <td>1.71976</td>\n",
       "      <td>1.75911</td>\n",
       "      <td>1.79005</td>\n",
       "      <td>1.79982</td>\n",
       "      <td>1.80607</td>\n",
       "      <td>1.82915</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50664</td>\n",
       "      <td>2.49739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3927.619629</td>\n",
       "      <td>4242.252930</td>\n",
       "      <td>3087.894775</td>\n",
       "      <td>3057.747803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.508805</td>\n",
       "      <td>0.253413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.69102</td>\n",
       "      <td>1.69771</td>\n",
       "      <td>1.71976</td>\n",
       "      <td>1.75911</td>\n",
       "      <td>1.79005</td>\n",
       "      <td>1.79982</td>\n",
       "      <td>1.80607</td>\n",
       "      <td>1.82915</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50664</td>\n",
       "      <td>2.49739</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3927.619629</td>\n",
       "      <td>4242.252930</td>\n",
       "      <td>3087.894775</td>\n",
       "      <td>3057.747803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.508805</td>\n",
       "      <td>0.253413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.93513</td>\n",
       "      <td>1.89559</td>\n",
       "      <td>1.86932</td>\n",
       "      <td>1.90935</td>\n",
       "      <td>1.98080</td>\n",
       "      <td>1.99318</td>\n",
       "      <td>1.95349</td>\n",
       "      <td>1.94106</td>\n",
       "      <td>...</td>\n",
       "      <td>2.37006</td>\n",
       "      <td>2.37102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3932.473877</td>\n",
       "      <td>4246.456055</td>\n",
       "      <td>3089.189209</td>\n",
       "      <td>3057.191406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.438600</td>\n",
       "      <td>0.239568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.93513</td>\n",
       "      <td>1.89559</td>\n",
       "      <td>1.86932</td>\n",
       "      <td>1.90935</td>\n",
       "      <td>1.98080</td>\n",
       "      <td>1.99318</td>\n",
       "      <td>1.95349</td>\n",
       "      <td>1.94106</td>\n",
       "      <td>...</td>\n",
       "      <td>2.37006</td>\n",
       "      <td>2.37102</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3932.473877</td>\n",
       "      <td>4246.456055</td>\n",
       "      <td>3089.189209</td>\n",
       "      <td>3057.191406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.438600</td>\n",
       "      <td>0.239568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.08135</td>\n",
       "      <td>2.05691</td>\n",
       "      <td>2.07815</td>\n",
       "      <td>2.18668</td>\n",
       "      <td>2.30497</td>\n",
       "      <td>2.31644</td>\n",
       "      <td>2.25308</td>\n",
       "      <td>2.19605</td>\n",
       "      <td>...</td>\n",
       "      <td>2.34814</td>\n",
       "      <td>2.34674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3937.340088</td>\n",
       "      <td>4250.667969</td>\n",
       "      <td>3090.462158</td>\n",
       "      <td>3056.635010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.454209</td>\n",
       "      <td>0.234117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.29647</td>\n",
       "      <td>3.01018</td>\n",
       "      <td>2.66962</td>\n",
       "      <td>2.99720</td>\n",
       "      <td>2.85586</td>\n",
       "      <td>2.51142</td>\n",
       "      <td>2.32614</td>\n",
       "      <td>2.37667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94458</td>\n",
       "      <td>2.97026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.424891</td>\n",
       "      <td>0.330981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.17699</td>\n",
       "      <td>2.23255</td>\n",
       "      <td>2.24035</td>\n",
       "      <td>2.23581</td>\n",
       "      <td>2.24270</td>\n",
       "      <td>2.26433</td>\n",
       "      <td>2.26342</td>\n",
       "      <td>2.19927</td>\n",
       "      <td>...</td>\n",
       "      <td>2.16329</td>\n",
       "      <td>2.17224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.356100</td>\n",
       "      <td>0.159022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.30833</td>\n",
       "      <td>2.39600</td>\n",
       "      <td>2.58576</td>\n",
       "      <td>2.59177</td>\n",
       "      <td>2.54080</td>\n",
       "      <td>2.67114</td>\n",
       "      <td>2.84325</td>\n",
       "      <td>2.72241</td>\n",
       "      <td>...</td>\n",
       "      <td>2.37106</td>\n",
       "      <td>2.36474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.926279</td>\n",
       "      <td>0.286341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.22116</td>\n",
       "      <td>2.11026</td>\n",
       "      <td>2.04835</td>\n",
       "      <td>2.01875</td>\n",
       "      <td>1.98500</td>\n",
       "      <td>1.94996</td>\n",
       "      <td>1.92805</td>\n",
       "      <td>1.93649</td>\n",
       "      <td>...</td>\n",
       "      <td>2.24696</td>\n",
       "      <td>2.24458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.507607</td>\n",
       "      <td>0.353157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208019</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.45390</td>\n",
       "      <td>2.34546</td>\n",
       "      <td>2.34054</td>\n",
       "      <td>2.40223</td>\n",
       "      <td>2.43364</td>\n",
       "      <td>2.41383</td>\n",
       "      <td>2.38355</td>\n",
       "      <td>2.35874</td>\n",
       "      <td>...</td>\n",
       "      <td>2.31823</td>\n",
       "      <td>2.31161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.734982</td>\n",
       "      <td>0.263542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208020 rows × 1762 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x     y      l_1      l_2      l_3      l_4      l_5      l_6  \\\n",
       "0       0.0   0.0  1.69102  1.69771  1.71976  1.75911  1.79005  1.79982   \n",
       "1       0.0   0.0  1.69102  1.69771  1.71976  1.75911  1.79005  1.79982   \n",
       "2       0.0   5.0  1.93513  1.89559  1.86932  1.90935  1.98080  1.99318   \n",
       "3       0.0   5.0  1.93513  1.89559  1.86932  1.90935  1.98080  1.99318   \n",
       "4       0.0  10.0  2.08135  2.05691  2.07815  2.18668  2.30497  2.31644   \n",
       "...     ...   ...      ...      ...      ...      ...      ...      ...   \n",
       "208015  0.0   0.0  2.29647  3.01018  2.66962  2.99720  2.85586  2.51142   \n",
       "208016  0.0   0.0  2.17699  2.23255  2.24035  2.23581  2.24270  2.26433   \n",
       "208017  0.0   0.0  2.30833  2.39600  2.58576  2.59177  2.54080  2.67114   \n",
       "208018  0.0   0.0  2.22116  2.11026  2.04835  2.01875  1.98500  1.94996   \n",
       "208019  0.0   0.0  2.45390  2.34546  2.34054  2.40223  2.43364  2.41383   \n",
       "\n",
       "            l_7      l_8  ...   l_1751   l_1752  perm          vp0  \\\n",
       "0       1.80607  1.82915  ...  2.50664  2.49739   0.0  3927.619629   \n",
       "1       1.80607  1.82915  ...  2.50664  2.49739  90.0  3927.619629   \n",
       "2       1.95349  1.94106  ...  2.37006  2.37102   0.0  3932.473877   \n",
       "3       1.95349  1.94106  ...  2.37006  2.37102  90.0  3932.473877   \n",
       "4       2.25308  2.19605  ...  2.34814  2.34674   0.0  3937.340088   \n",
       "...         ...      ...  ...      ...      ...   ...          ...   \n",
       "208015  2.32614  2.37667  ...  2.94458  2.97026   NaN          NaN   \n",
       "208016  2.26342  2.19927  ...  2.16329  2.17224   NaN          NaN   \n",
       "208017  2.84325  2.72241  ...  2.37106  2.36474   NaN          NaN   \n",
       "208018  1.92805  1.93649  ...  2.24696  2.24458   NaN          NaN   \n",
       "208019  2.38355  2.35874  ...  2.31823  2.31161   NaN          NaN   \n",
       "\n",
       "               vp90          vs0         vs90  e_star    l_mean     l_std  \n",
       "0       4242.252930  3087.894775  3057.747803     NaN  2.508805  0.253413  \n",
       "1       4242.252930  3087.894775  3057.747803     NaN  2.508805  0.253413  \n",
       "2       4246.456055  3089.189209  3057.191406     NaN  2.438600  0.239568  \n",
       "3       4246.456055  3089.189209  3057.191406     NaN  2.438600  0.239568  \n",
       "4       4250.667969  3090.462158  3056.635010     NaN  2.454209  0.234117  \n",
       "...             ...          ...          ...     ...       ...       ...  \n",
       "208015          NaN          NaN          NaN     NaN  3.424891  0.330981  \n",
       "208016          NaN          NaN          NaN     NaN  2.356100  0.159022  \n",
       "208017          NaN          NaN          NaN     NaN  2.926279  0.286341  \n",
       "208018          NaN          NaN          NaN     NaN  2.507607  0.353157  \n",
       "208019          NaN          NaN          NaN     NaN  2.734982  0.263542  \n",
       "\n",
       "[208020 rows x 1762 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing\n",
    "\n",
    "1. pre-clean the dataset\n",
    " - remove duplicated rows\n",
    " - enforce correct dtypes \n",
    " - reduce memory overhead\n",
    " - do not remove missing values\n",
    "1. create a set of variables to summarize the ftir data\n",
    "1. visualize\n",
    " - relations in the dataset suing `hip.Experiment.from_dataframe(df).display()`\n",
    " - distribution of missing values  `klib.missingval_plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-cleaning\n",
    "first cleaning of the data before inputation.\n",
    "overwrite the df since there is no need to refer to it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the record print the information of the original dataframe\n",
    "dfinfo(df, 'raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-clean, do not remove missing values\n",
    "df = klib.data_cleaning(df, drop_threshold_rows = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the information of the cleaned dataframe\n",
    "dfinfo(df, 'raw data cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ftir stats (basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize\n",
    "### feature flow with hip\n",
    "in this step the features of the ftir can be summarized within the feature `l_mean`\n",
    "\n",
    "visualize the flow of values in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hip_visualize(df, df.columns[-9:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing values wtih klib\n",
    "use `klib` to visualize the missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klib.missingval_plot(df.loc[:,pcols]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing values & outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_ix = df.index.droplevel(6).drop_duplicates()\n",
    "ds = desc.loc[desc_ix].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = 'vel'\n",
    "\n",
    "# get the columns for velocity\n",
    "vcols = pp.probe_settings[probe]['col'][:4]\n",
    "\n",
    "# get min and max expected for measurement\n",
    "vmin, vmax = pp.probe_settings[probe]['limits']\n",
    "\n",
    "# pcols = df.columns[df.columns.str.startswith(probe[0])]\n",
    "ncols = len(vcols[2:])\n",
    "\n",
    "# checkout features\n",
    "dv = df.loc[:, vcols[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfinfo(dv, 'info of raw')\n",
    "## firtst check how they are distributed\n",
    "pprint(dv.describe().apply(np.round, decimals = 2), 'raw data')\n",
    "\n",
    "## identify offending values and those to keep\n",
    "vix = probeix(dv.iloc[:, -1], vmin = vmin, vmax = vmax)\n",
    "\n",
    "## set nan for all incorrect values\n",
    "dv.iloc[vix.values == False, -1] = np.nan\n",
    "pprint(dv.describe().apply(np.round, decimals = 2), 'correct measurements')\n",
    "\n",
    "# get the labels that have problem\n",
    "out, ix = get_wrong_measurements(dv.iloc[:, -1], probe = probe, desc = ds, vmin = vmin, vmax = vmax)\n",
    "ixd = ixdp = dv.loc[ix == True].index\n",
    "ixdn = dv.loc[ix == False].index\n",
    "\n",
    "pprint(dv.loc[ix, :].describe().apply(np.round, decimals = 2), 'only approved samples')\n",
    "\n",
    "# the ix returned from `get_wrong_measurements` keeps only samples where  more than a threshold percent (`th`) of values are correct.\n",
    "# samples that don't meet this criteria are lost. This is different than probeix, which only asserts if the values are within a range independently of their sample. \n",
    "\n",
    "# ix can be used to do basic data inputation on the sample, for example by filling it with the mean\n",
    "dp = dv.copy()\n",
    "dp.loc[ix, :] = dv.loc[ix, :].groupby(level = ds.index.names).apply(interp_on_nans)\n",
    "pprint(dp.describe().apply(np.round, decimals = 2), 'correct & interp data (all samples)')\n",
    "\n",
    "dp = dp.groupby(level = ds.index.names).apply(lambda x: x.fillna(x.mean()))\n",
    "pprint(dp.describe().apply(np.round, decimals = 2), 'correct & interp data (all samples, fillna)')\n",
    "# dv.iloc[[ix == True], -1] = dv.iloc[ix == True, -1].groupby(level = desc.index.names).apply(lambda x: x.fillna(x.mean()))\n",
    "# # ixs = dv.dropna().index\n",
    "\n",
    "# # set all the samples that did not meet the criteria to nan\n",
    "# # dv2 = dv.copy()\n",
    "# # dv2.loc[mix[ix == False, :]] = np.nan\n",
    "# # dfinfo(dv2, 'info of mix')\n",
    "\n",
    "pprint('index\\t len\\t +\\t -\\t \\nvix\\t %d \\nix\\t %d \\t %d \\t %d \\nixd\\t %d \\t %d \\t %d' \n",
    "       % tuple([len(x) for x in [vix, ix, ix[ix == True], ix[ix == False], ixd, ixdp, ixdn]]),\n",
    "      'index lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.loc[:, vcols[-1]].dropna().groupby('code').hist();#agg({vcols[-1] : ['mean', 'std', 'median','count']})\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "dp.loc[ix, vcols[-1]].groupby(level = 'code').plot(kind = 'kde', y = vcols[-1], grid = True, ax = ax, label = 'code');\n",
    "#hist(by = 'code', column = vcols[-1], sharex = True, sharey = True);\n",
    "# ds = pd.DataFrame(columns = ['step', vcols[-1]])\n",
    "# [d.loc[k, vcols[-1]].reset_index(drop = True) for k in [[True]*dv.shape[0], vix, ix] for d in [dv, dp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.append(velcols, [permcol, hammcol])\n",
    "v = np.append(['family','code'], v)\n",
    "df2 = df.loc[ix, :].reset_index(drop = False)\n",
    "# df2.loc[ixd.values, v.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.violinplot.html\n",
    "# https://levelup.gitconnected.com/scikit-learn-python-6-useful-tricks-for-data-scientists-1a0a502a6aa3\n",
    "# https://towardsdatascience.com/speed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80\n",
    "# https://pythondata.com/dask-large-csv-python/\n",
    "# https://github.com/wiseio/paratext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# perm = df.loc[:, [permcol]]\n",
    "# pprint(perm.describe())\n",
    "# permidx = probeix(perm, vmin = 0, vmax = np.inf)\n",
    "# ## check the data makes sense\n",
    "# pprint(perm.loc[permidx, :].describe())\n",
    "\n",
    "# ## print the labels that have problem\n",
    "# out, _  = get_wrong_measurements(perm, 'perm', desc)\n",
    "# out.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klib.dist_plot(df2.loc[:, v[[1,2,3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.iloc[:, -1].groupby('code').apply(klib.dist_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove offending values and keep just good measurements\n",
    "idx = np.logical_and(velidx.values, permidx.values)\n",
    "dc = df.loc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative, fill the values with means or nans\n",
    "vels.loc[velidx == False, :] = np.nan\n",
    "desc.loc[vels.index[velidx == False].droplevel(6).drop_duplicates()].query(\"probe == 'vel'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = velidx[velidx == False].index.droplevel(6).drop_duplicates()\n",
    "# for t in x:\n",
    "#     vels.loc[mix[[*t], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = vels.groupby(level = velidx.index.names[:-1], sort = False).apply(np.mean)\n",
    "\n",
    "# for dd in means.index:\n",
    "#     pass\n",
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix = pd.IndexSlice\n",
    "# mix[[*ix], :]\n",
    "# vels.loc(axis = 0)[mix[[dd], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myquery(x, vels, velmin = 0.5e3, velmax = v):\n",
    "#     v = vels.copy()\n",
    "#     s = v.loc[x, :].shape[0]\n",
    "#     idx = np.logical_and((v >= velmin).all(axis = 1), (v <= velmax).all(axis = 1))\n",
    "#     skeep = np.sum(idx)\n",
    "#     sdrop = np.sum(idx == False)\n",
    "#     return s, skeep, sdrop\n",
    "\n",
    "# for a, b in idx.loc[revise_idx, :].groupby(level = idx.index.names[2:-1]):\n",
    "#     pass#.describe()\n",
    "\n",
    "# x = revise_idx.droplevel(6).drop_duplicates()\n",
    "# idx.loc[slice(x, :), :]\n",
    "\n",
    "# idx.loc[revise_idx, :]\n",
    "# idx.groupby(level = idx.index.names[2:-1]).describe()\n",
    "# .loc[:, 'r'] = 'review'\n",
    "\n",
    "# mix = pd.IndexSlice\n",
    "# pd.concat((idx.loc[mix[[*t], :]] for t in x)) \n",
    "\n",
    "# mix = pd.IndexSlice\n",
    "# pd.concat((idx.loc[mix[[*t], :]] for t in x)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:numerics] *",
   "language": "python",
   "name": "conda-env-numerics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
