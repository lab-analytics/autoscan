{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def probeix(df, vmin, vmax):\n",
    "    return np.logical_and((df >= vmin).all(axis = 1), (df <= vmax).all(axis = 1))\n",
    "\n",
    "def get_wrong_measurements(df, idx, probe, desc, th = 0.5):\n",
    "#     desc2 = desc.sort_index()\n",
    "    x = idx[idx == False].index.droplevel(6).drop_duplicates()\n",
    "    d = []\n",
    "    s = [((idx.xs(t, level = x.names) == True).sum() / idx.xs(t, level = x.names).shape[0]) for t in x]\n",
    "    out = desc.loc[x[np.array(s) < th]].query(\"probe == '%s'\" % (probe))\n",
    "    return out, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/nuburu/sandbox/data/characterization/autoscan/autoscan.h5'\n",
    "savepath = '/home/nuburu/Documents/'\n",
    "\n",
    "# load the data\n",
    "df = pd.read_hdf(datapath, key = 'data')\n",
    "desc = pd.read_hdf(datapath, key = 'description')\n",
    "\n",
    "velcols = df.columns[-4:-2]\n",
    "permcol = 'perm'\n",
    "hammcol = 'e_star'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check velocities\n",
    "vels = df.loc[:, velcols]\n",
    "## firtst check how they are distributed\n",
    "vels.describe().loc[['mean', 'min', 'max'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify offending values and those to keep\n",
    "velmin = 0.5e3\n",
    "velmax = 7.0e3\n",
    "velidx = probeix(vels, vmin = velmin, vmax = velmax)\n",
    "\n",
    "## check the data makes sense\n",
    "print(vels.loc[velidx, :].describe())\n",
    "\n",
    "## print the labels that have problem\n",
    "out, _ = get_wrong_measurements(vels, velidx, 'vel', desc)\n",
    "out.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = df.loc[:, [permcol]]\n",
    "print(perm.describe())\n",
    "permidx = probeix(perm, vmin = 0.3, vmax = 5e3)\n",
    "## check the data makes sense\n",
    "print(perm.loc[permidx, :].describe())\n",
    "\n",
    "## print the labels that have problem\n",
    "out, _  = get_wrong_measurements(perm, permidx, 'perm', desc)\n",
    "out.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove offending values and keep just good measurements\n",
    "idx = np.logical_and(velidx.values, permidx.values)\n",
    "dc = df.loc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative, fill the values with means or nans\n",
    "vels.loc[velidx == False, :] = np.nan\n",
    "desc.loc[vels.index[velidx == False].droplevel(6).drop_duplicates()].query(\"probe == 'vel'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = velidx[velidx == False].index.droplevel(6).drop_duplicates()\n",
    "# for t in x:\n",
    "#     vels.loc[mix[[*t], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = vels.groupby(level = velidx.index.names[:-1], sort = False).apply(np.mean)\n",
    "\n",
    "# for dd in means.index:\n",
    "#     pass\n",
    "# dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix = pd.IndexSlice\n",
    "# mix[[*ix], :]\n",
    "# vels.loc(axis = 0)[mix[[dd], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myquery(x, vels, velmin = 0.5e3, velmax = v):\n",
    "#     v = vels.copy()\n",
    "#     s = v.loc[x, :].shape[0]\n",
    "#     idx = np.logical_and((v >= velmin).all(axis = 1), (v <= velmax).all(axis = 1))\n",
    "#     skeep = np.sum(idx)\n",
    "#     sdrop = np.sum(idx == False)\n",
    "#     return s, skeep, sdrop\n",
    "\n",
    "# for a, b in idx.loc[revise_idx, :].groupby(level = idx.index.names[2:-1]):\n",
    "#     pass#.describe()\n",
    "\n",
    "# x = revise_idx.droplevel(6).drop_duplicates()\n",
    "# idx.loc[slice(x, :), :]\n",
    "\n",
    "# idx.loc[revise_idx, :]\n",
    "# idx.groupby(level = idx.index.names[2:-1]).describe()\n",
    "# .loc[:, 'r'] = 'review'\n",
    "\n",
    "# mix = pd.IndexSlice\n",
    "# pd.concat((idx.loc[mix[[*t], :]] for t in x)) \n",
    "\n",
    "# mix = pd.IndexSlice\n",
    "# pd.concat((idx.loc[mix[[*t], :]] for t in x)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:numerics] *",
   "language": "python",
   "name": "conda-env-numerics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
