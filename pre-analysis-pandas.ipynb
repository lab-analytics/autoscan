{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing with dask\n",
    "import os, sys, re, io, pathlib\n",
    "import pandas as pd\n",
    "import hiplot as hip\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "buffer = io.StringIO()\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# define the current path (notebooks in lab_utils)\n",
    "labutilspath = str(pathlib.Path(os.getcwd()).parents[1])\n",
    "sys.path.append(labutilspath)\n",
    "\n",
    "# import the autoscan routines\n",
    "from autoscan import autoscan\n",
    "\n",
    "pp = autoscan.basics(material_info = True)\n",
    "\n",
    "def pprint(msg, msg_title = '', msg_decorator = '#', len_decorator = 40):\n",
    "    nhead = len_decorator - len(msg_title) - 2\n",
    "    if nhead <= 0:\n",
    "        nhead = 1\n",
    "        nfoot = len(msg_title) + 4\n",
    "    else:\n",
    "        nfoot = len_decorator\n",
    "    \n",
    "    top_decorator = msg_decorator * (nhead // 2) \n",
    "    print(top_decorator + ' ' + msg_title  +  ' ' + top_decorator, \n",
    "          msg, nfoot * '#' + '\\n',\n",
    "          sep = '\\n')\n",
    "    return\n",
    "\n",
    "def dfinfo(df, header = 'info'):\n",
    "    with io.StringIO() as buffer:\n",
    "        df.info(buf = buffer)\n",
    "        pprint(buffer.getvalue(), msg_title = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define important columns (categorical and numerical)\n",
    "ftir_cols = pp.probe_settings['ftir']['col'][2:]\n",
    "tips_cols = list(itertools.chain(*[p['col'][2:] for _, p in pp.probe_settings.items()]))\n",
    "ftir_lambdas = pp.probe_settings['ftir']['lambdas']\n",
    "\n",
    "col_numerical = ['x', 'y'] + tips_cols + ['l_max_peak', 'l_min_peak']\n",
    "col_categorical = ['family', 'code', 'tag', 'subtag', 'instance', 'experiment', 'side', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "datapath = '/sandbox/data/autoscan/'\n",
    "datafile = os.path.join(datapath, 'autoscan.h5')\n",
    "savepath = datapath\n",
    "\n",
    "df = pd.read_hdf(datafile, key = 'data')\n",
    "df_description = pd.read_hdf(datafile, key = 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix some tags\n",
    "df.loc[df.tag.str.contains('eur'), 'family'] = 'shale'\n",
    "df.loc[df.tag.str.contains('eur'), 'code'] = 'sh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.loc[:, ['tag']]\n",
    "ds = ds.assign(rho = 0.0)\n",
    "ds = ds.assign(\n",
    "    basetag = ds.tag.str.split('_', expand = True, n = 1)[0].values\n",
    ")\n",
    "\n",
    "for t in ds.basetag.unique():\n",
    "    ds['rho'] = ds['rho'].mask(ds['basetag'] == t, pp.get_material_density(t))\n",
    "\n",
    "ds.index.name = 'ix'\n",
    "# ds = ds.set_index(['code', ds.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_peak_to_lambda(x):\n",
    "    if np.logical_and(x != np.nan, type(x) == str):\n",
    "        out = ftir_lambdas[int(x.split('_')[1]) - 1]\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "def ftir_row_stats(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            l_mean = lambda df: df.loc[:, ftir_cols].mean(axis = 1),          \n",
    "            l_std = lambda df: df.loc[:, ftir_cols].std(axis = 1),\n",
    "            # l_median = lambda df: np.median(df.iloc[:, 2:1754], axis = 1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def ftir_extreme_locations(df):\n",
    "    idx_max_peaks = df.loc[:, ftir_cols].idxmax(axis = 1)\n",
    "    idx_min_peaks = df.loc[:, ftir_cols].idxmin(axis = 1)\n",
    "    return (\n",
    "        df\n",
    "        .assign(\n",
    "            l_max_peak = idx_max_peaks.apply(lambda x: idx_peak_to_lambda(x)),\n",
    "            l_min_peak = idx_min_peaks.apply(lambda x: idx_peak_to_lambda(x))        \n",
    "        )\n",
    "    \n",
    "    )\n",
    "    \n",
    "def clean_dataframe(df):\n",
    "    return (\n",
    "        df\n",
    "        .where(df >= 0, np.nan)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "\n",
    "def enforce_limits(df):\n",
    "    for k, p in pp.probe_settings.items():\n",
    "        v = p['col'][2:]\n",
    "        vmin, vmax = p['limits']\n",
    "        df[v] = df[v].where(((df[v] >= vmin) & (df[v] <= vmax)), np.nan)\n",
    "    return df\n",
    "\n",
    "def hip_visualize(df, pcols = None, index = ['family', 'code']):\n",
    "    dp = df.reset_index().loc[:, np.append(index, pcols)]\n",
    "    s = hip.Experiment.from_dataframe(dp)\n",
    "    s.colormap = 'interpolateViridis'\n",
    "    s.display()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, tips_cols[:8]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce limits, set non-physical values to nan\n",
    "df = enforce_limits(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, tips_cols[:8]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mechanical properties\n",
    "vcols = ['vp0', 'vs0', 'vp90', 'vs90']\n",
    "vels  = df.loc[:, vcols].values\n",
    "vels2 = np.power(vels, 2)\n",
    "rho = ds.loc[:, 'rho'].values.reshape(ds.shape[0], 1)\n",
    "\n",
    "E = np.multiply(rho, np.multiply(vels2[:, 1::2], 3.0 * vels2[:, 0::2] - 4.0 * vels2[:, 1::2]))\n",
    "df.loc[:, ['mech_e0', 'mech_e90']] = np.divide(E, vels2[:, 0::2] - vels2[:, 1::2]) / 1e6\n",
    "df.loc[:, ['mech_l0', 'mech_l90']] = np.multiply(rho, vels2[:, 0::2] - 2.0 * vels2[:, 1::2])\n",
    "df.loc[:, ['mech_k0', 'mech_k90']] = np.multiply(rho, vels2[:, 0::2] - (4 / 3) * vels2[:, 1::2]) / 1e6\n",
    "df.loc[:, ['mech_n0', 'mech_n90']] = np.divide(vels2[:, 0::2] - 2.0 * vels2[:, 1::2], 2.* (vels2[:, 0::2] - vels2[:, 1::2]))\n",
    "df.loc[:, ['mech_i0', 'mech_i90']] = np.multiply(rho, vels[:, 0::2])\n",
    "df.loc[:, ['mech_m0', 'mech_m90']] = np.multiply(rho, vels2[:, 0::2])\n",
    "df.loc[:, ['mech_g0', 'mech_g90']] = np.multiply(rho, vels2[:, 1::2])\n",
    "df.loc[:, 'rho'] = rho\n",
    "\n",
    "# remove the data we don't need\n",
    "del E, rho, vels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechs = df.columns[df.columns.str.contains('mech')]\n",
    "df.loc[:, mechs].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which values do not make sense. -1 <= pr <= 0.5\n",
    "for i in ['0', '90']:\n",
    "    ix = np.logical_and(df.loc[:, 'mech_n'+i] >= -1, df.loc[:, 'mech_n'+i] <= 1.0)\n",
    "    temp_cols = df.columns[df.columns.str.contains(r'mech[_][a-z]'+i)]\n",
    "    df.loc[ix == False, temp_cols] = np.nan\n",
    "    df.loc[ix == False, col_categorical[:-1]].drop_duplicates().merge(df_description.loc[df_description.probe == 'vels'], on = col_categorical[:-1]).to_csv(os.path.join(savepath, 'repeat_vels_' + i + '.csv'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the peaks of the ftir\n",
    "df = ftir_extreme_locations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-minute",
   "metadata": {},
   "source": [
    "# data cleaning\n",
    "1. pre-clean the dataset\n",
    " - remove duplicated rows\n",
    " - enforce correct dtypes \n",
    " - reduce memory overhead\n",
    " - do not remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the record print the information of the original dataframe\n",
    "dfinfo(df, 'raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import klib\n",
    "# # pre-clean, do not remove missing values\n",
    "# df = klib.data_cleaning(df, drop_threshold_rows = 1.0, clean_col_names = False)\n",
    "# df.loc[:, col_categorical] = df.loc[:, col_categorical].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downcast to float32 to save some memory. this is likely useless in the current context. \n",
    "# df = df.apply(pd.to_numeric, downcast = 'float', errors = 'ignore')\n",
    "# df.loc[:, col_categorical] = df.loc[:, col_categorical].astype('category')\n",
    "# print the information of the cleaned dataframe\n",
    "# dfinfo(df, 'raw data cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-accident",
   "metadata": {},
   "source": [
    "## fix values and correct information\n",
    "1. set nan to measurements where all values are the same (ftir)\n",
    "2. set the correct family and code for eur samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = df.loc[:, ftir_cols].apply(lambda x: len(np.unique(x)), axis = 1) == 1\n",
    "df.loc[ix, ftir_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, col_numerical].to_hdf(os.path.join(savepath, 'autoscan_corrected.h5'), key = 'data', format = 'table', mode = 'w')\n",
    "df.loc[:, col_categorical].to_hdf(os.path.join(savepath, 'autoscan_corrected.h5'), key = 'desc', mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_ftir = df.loc[ix, :].set_index(col_categorical[:-1]).index.unique()\n",
    "pd.DataFrame.from_records(repeat_ftir.to_numpy(), columns = col_categorical[:-1]).to_csv(os.path.join(savepath, 'ftir_repeat.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-complement",
   "metadata": {},
   "source": [
    "# visualization\n",
    "1. hip-plot (again) but with corrected data\n",
    "2. distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-remedy",
   "metadata": {},
   "source": [
    "## hip\n",
    "### without `e_star`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mech_cols = df.columns[df.columns.str.contains(r'mech[_][a-z]0')].values\n",
    "mech_cols = ['mech_' + s + '0' for s in ['e', 'k','n']]\n",
    "subset_cols = ['l_max_peak', 'perm'] + list(mech_cols)\n",
    "print(subset_cols)\n",
    "s = hip_visualize(df.query(\"instance == 'before'\").dropna(subset = subset_cols), \n",
    "                  pcols = subset_cols, \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_before_woestar.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'after'\").dropna(subset = subset_cols), \n",
    "                  pcols = subset_cols, \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_before_westar.html'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-silence",
   "metadata": {},
   "source": [
    "### with `e_star`\n",
    "the number of samples with impulse hammer measurements are 1/4th of the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols += ['e_star']\n",
    "s = hip_visualize(df.query(\"instance == 'before'\").dropna(subset = subset_cols), \n",
    "                  pcols = subset_cols, \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_after_woestar.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'after'\").dropna(subset = subset_cols), \n",
    "                  pcols = subset_cols, \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_after_westar.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = subset_cols[1:-1]\n",
    "s = hip_visualize(df.query(\"instance == 'before'\").dropna(subset = subset_cols), \n",
    "                  pcols = subset_cols, \n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_before_permvel.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hip_visualize(df.query(\"instance == 'after'\").dropna(subset = subset_cols), \n",
    "                  pcols = subset_cols,\n",
    "                  index = ['code'])\n",
    "\n",
    "s.to_html(os.path.join(savepath, 'hip_after_permvel.html'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = df.query(\"instance == 'before'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_perm = df_before.perm.isna() == False\n",
    "df_perm_before = df_before.loc[ix_perm, ['family', 'code', 'perm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.stripplot(y = 'perm', x = 'family', hue = 'code', data = df_perm_before, palette = 'viridis', ax = ax)\n",
    "plt.yscale('log')\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.violinplot(y = 'perm', x = 'code', hue = 'family', data = df_perm_before, palette = 'viridis', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perm_before_clipped = df_perm_before.copy()\n",
    "df_perm_before_clipped.loc[:, 'perm'] = df_perm_before_clipped.perm.clip(lower = 0, upper = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.violinplot(y = 'perm', x = 'code', hue = 'family', data = df_perm_before_clipped, palette = 'viridis', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.boxplot(y = 'perm', x = 'code', hue = 'family', data = df_perm_before_clipped, palette = 'viridis', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "sns.kdeplot(x = 'perm',  hue = 'code', data = df_perm_before_clipped, \n",
    "            palette = 'viridis', shade = 'fill', ax = ax)\n",
    "sns.set_style('darkgrid')\n",
    "plt.title('permeability before');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ds.tag.str.split('_', expand = True)#.apply(lambda x: pp.get_material_density(x))\n",
    "tags[1] = 0.0\n",
    "unique_tags = tags[0].unique()\n",
    "# tags.set_index([0, tags.index], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-concentration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:numerics] *",
   "language": "python",
   "name": "conda-env-numerics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
