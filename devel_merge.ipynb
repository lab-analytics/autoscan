{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from pandas import HDFStore,DataFrame\n",
    "# define the current path (notebooks in lab_utils)\n",
    "currpath = os.getcwd()\n",
    "labutilspath = str(Path(currpath).parents[1])\n",
    "sys.path.append(labutilspath)\n",
    "\n",
    "# import the autoscan routines\n",
    "from autoscan import autoscan\n",
    "\n",
    "# define paths\n",
    "basepath = '/home/urlab/sandbox/data/autoscan/'\n",
    "\n",
    "# set the asdatapath accordingly (where is the atuoscan data inside basedatapath?)\n",
    "asdatapath   = 'new_measurements'\n",
    "\n",
    "# set datapath\n",
    "datapath = os.path.join(basepath, asdatapath)\n",
    "\n",
    "pp = autoscan.postprocess(labutilspath=labutilspath)\n",
    "pp.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the summary dataframe with all measurement\n",
    "summary = pd.read_csv(os.path.join(datapath,'summary.csv'))\n",
    "# remove ztop and zbottom\n",
    "t = summary['relroot'].apply(lambda x: len(re.findall(r'ztop|zbottom', x))==0)\n",
    "summary = summary.loc[t,:].copy()\n",
    "\n",
    "sample_info = pp._subset_info(summary, instance = instance, sample_tag = tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_tag</th>\n",
       "      <th>subsample_tag</th>\n",
       "      <th>sample_code</th>\n",
       "      <th>sample_family</th>\n",
       "      <th>probe</th>\n",
       "      <th>side</th>\n",
       "      <th>instance</th>\n",
       "      <th>fname</th>\n",
       "      <th>relroot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wsg_002</td>\n",
       "      <td>plugs</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>ftir</td>\n",
       "      <td>3.0</td>\n",
       "      <td>before</td>\n",
       "      <td>ftir_before_3.csv</td>\n",
       "      <td>wsg_002/subsamples/plugs/processed/ftir_before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wsg_002</td>\n",
       "      <td>plugs</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>ftir</td>\n",
       "      <td>2.0</td>\n",
       "      <td>before</td>\n",
       "      <td>ftir_before_2.csv</td>\n",
       "      <td>wsg_002/subsamples/plugs/processed/ftir_before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wsg_002</td>\n",
       "      <td>plugs</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>perm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before</td>\n",
       "      <td>perm_before.csv</td>\n",
       "      <td>wsg_002/subsamples/plugs/processed/perm_before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wsg_002</td>\n",
       "      <td>plugs</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>ftir</td>\n",
       "      <td>6.0</td>\n",
       "      <td>before</td>\n",
       "      <td>ftir_before_6.csv</td>\n",
       "      <td>wsg_002/subsamples/plugs/processed/ftir_before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wsg_002</td>\n",
       "      <td>plugs</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>ftir</td>\n",
       "      <td>1.0</td>\n",
       "      <td>before</td>\n",
       "      <td>ftir_before_1.csv</td>\n",
       "      <td>wsg_002/subsamples/plugs/processed/ftir_before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>wsg_003</td>\n",
       "      <td>s4</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>vel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before</td>\n",
       "      <td>vel_before.csv</td>\n",
       "      <td>wsg_003/subsamples/s4/processed/vel_before.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>wsg_003</td>\n",
       "      <td>s3</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>perm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before</td>\n",
       "      <td>perm_before.csv</td>\n",
       "      <td>wsg_003/subsamples/s3/processed/perm_before.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>wsg_003</td>\n",
       "      <td>s3</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>vel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before</td>\n",
       "      <td>vel_before.csv</td>\n",
       "      <td>wsg_003/subsamples/s3/processed/vel_before.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>wsg_003</td>\n",
       "      <td>s2</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>perm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before</td>\n",
       "      <td>perm_before.csv</td>\n",
       "      <td>wsg_003/subsamples/s2/processed/perm_before.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>wsg_003</td>\n",
       "      <td>s2</td>\n",
       "      <td>sg</td>\n",
       "      <td>sandstone</td>\n",
       "      <td>vel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before</td>\n",
       "      <td>vel_before.csv</td>\n",
       "      <td>wsg_003/subsamples/s2/processed/vel_before.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_tag subsample_tag sample_code sample_family probe  side instance  \\\n",
       "0     wsg_002         plugs          sg     sandstone  ftir   3.0   before   \n",
       "1     wsg_002         plugs          sg     sandstone  ftir   2.0   before   \n",
       "2     wsg_002         plugs          sg     sandstone  perm   NaN   before   \n",
       "3     wsg_002         plugs          sg     sandstone  ftir   6.0   before   \n",
       "4     wsg_002         plugs          sg     sandstone  ftir   1.0   before   \n",
       "..        ...           ...         ...           ...   ...   ...      ...   \n",
       "63    wsg_003            s4          sg     sandstone   vel   NaN   before   \n",
       "64    wsg_003            s3          sg     sandstone  perm   NaN   before   \n",
       "65    wsg_003            s3          sg     sandstone   vel   NaN   before   \n",
       "66    wsg_003            s2          sg     sandstone  perm   NaN   before   \n",
       "67    wsg_003            s2          sg     sandstone   vel   NaN   before   \n",
       "\n",
       "                fname                                            relroot  \n",
       "0   ftir_before_3.csv  wsg_002/subsamples/plugs/processed/ftir_before...  \n",
       "1   ftir_before_2.csv  wsg_002/subsamples/plugs/processed/ftir_before...  \n",
       "2     perm_before.csv  wsg_002/subsamples/plugs/processed/perm_before...  \n",
       "3   ftir_before_6.csv  wsg_002/subsamples/plugs/processed/ftir_before...  \n",
       "4   ftir_before_1.csv  wsg_002/subsamples/plugs/processed/ftir_before...  \n",
       "..                ...                                                ...  \n",
       "63     vel_before.csv     wsg_003/subsamples/s4/processed/vel_before.csv  \n",
       "64    perm_before.csv    wsg_003/subsamples/s3/processed/perm_before.csv  \n",
       "65     vel_before.csv     wsg_003/subsamples/s3/processed/vel_before.csv  \n",
       "66    perm_before.csv    wsg_003/subsamples/s2/processed/perm_before.csv  \n",
       "67     vel_before.csv     wsg_003/subsamples/s2/processed/vel_before.csv  \n",
       "\n",
       "[68 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dfs = []\n",
    "# for s in sample_info.itertuples(index=False):\n",
    "#     relpath = getattr(s, 'relroot')\n",
    "#     probe   = getattr(s, 'probe')\n",
    "#     data = pp.read_data(os.path.join(datapath, relpath), probe = probe)\n",
    "#     h = pp.probe_settings[probe]['h']\n",
    "#     data = data.iloc[:,:h]\n",
    "#     if probe == 'vel':\n",
    "#         for x in data.angle.unique():\n",
    "#             dfs.append(data.loc[data['angle'] == x,:].copy().drop(columns = 'angle'))\n",
    "#     else:\n",
    "#         dfs.append(data)\n",
    "\n",
    "# df_merged = reduce(lambda left,right: pd.merge(left,right,on=['x','y'], how ='inner'), dfs)\n",
    "# df_merged = pp._enforce_float(df_merged)\n",
    "# df_merged['tag'] = tag\n",
    "# df_merged['instance'] = instance\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "fullset = []\n",
    "problem = {}\n",
    "problem_merged = []\n",
    "ns = 0\n",
    "for instace in ['before', 'after']:\n",
    "    for tag in summary['sample_tag'].unique():\n",
    "        s1 = pp._subset_info(summary, instance = instance, sample_tag = tag)\n",
    "        if len(s1)>0:\n",
    "            family = s1['sample_family'].unique()[0]\n",
    "            code   = s1['sample_code'].unique()[0]\n",
    "            for subtag in s1['subsample_tag'].unique():\n",
    "                s2 = pp._subset_info(s1, subsample_tag = subtag, sample_code = code, sample_family = family)\n",
    "                for kside, side in enumerate(s2['side'].unique()):\n",
    "                    s3 = pp._subset_info(s2, side = side)\n",
    "                    probes  = s3['probe'].unique()\n",
    "                    nprobes = len(probes)\n",
    "                    if nprobes>=1 and ('ftir' in probes):\n",
    "                        dfs = []\n",
    "                        for meas in s3.itertuples(index=False):\n",
    "                            relpath  = getattr(meas, 'relroot')\n",
    "                            filepath = os.path.join(datapath, relpath)\n",
    "                            probe    = getattr(meas, 'probe')\n",
    "                            \n",
    "                            data     = pp.read_data(filepath, probe = probe)\n",
    "                            \n",
    "                            h    = pp.probe_settings[probe]['h']\n",
    "                            data = data.iloc[:,:h]\n",
    "\n",
    "                            if probe == 'vel':\n",
    "                                for k,x in enumerate(data.angle.unique()):\n",
    "                                    colnames = ['vp_'+str(k), 'vs_'+str(k)]\n",
    "                                    data_temp = data.loc[data['angle'] == x,:].copy().drop(columns = 'angle')\n",
    "                                    data_temp.columns = ['x','y'] + colnames\n",
    "                                    dfs.append(data_temp)\n",
    "                                    del data_temp\n",
    "                            else:\n",
    "                                dfs.append(data)\n",
    "\n",
    "                        df_merged = reduce(lambda left,right: pd.merge(left,right,on=['x','y'], how ='inner'), dfs)\n",
    "                        df_merged = pp._enforce_float(df_merged)\n",
    "                        if df_merged.shape[0]>0 and len(df_merged.iloc[:,1754:].columns.values)>=0:\n",
    "                            ns += df_merged.shape[0]\n",
    "                            df_merged['family']   = family\n",
    "                            df_merged['code']     = code\n",
    "                            df_merged['tag']      = tag\n",
    "                            df_merged['subtag']   = subtag\n",
    "                            df_merged['instance'] = instance\n",
    "                            df_merged['side']     = kside\n",
    "                            \n",
    "                            if save:\n",
    "                                outpath = pp._set_outpath(datapath,tag)\n",
    "                                outname = pp._set_outfilename(tag, subtag, side, instance, 'fullset')\n",
    "                                pp.save_data(df_merged, savepath = outpath,  savename = outname)\n",
    "                        \n",
    "                            fullset.append(df_merged.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns\n",
    "compiledinfocols = ['family', 'code', 'tag', 'subtag', 'side', 'instance']\n",
    "compileddatacols = pp.probe_settings['ftir']['names'][2:] + ['perm', 'vp_0', 'vs_0']  \n",
    "compiledfullcols = compiledinfocols + compileddatacols\n",
    "\n",
    "dfc = pd.concat(fullset, sort = False, axis = 0, ignore_index=True, join = 'outer')\n",
    "dfc = dfc.loc[:,compiledfullcols].copy()\n",
    "dfc.loc[:,compileddatacols] = dfc.loc[:,compileddatacols].apply(pd.to_numeric,errors='coerce').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['plugs', 's1', 's6', 's5', 's4', 's2', 's7', 's3'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.subtag.unique()\n",
    "# savefile = os.path.join(datapath, 'as_dataset.h5')\n",
    "# dfc.to_hdf(savefile, key = 'data', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dp\n",
    "dp.io.save(os.path.join(datapath, 'compiled.h5'), dfc)\n",
    "# dp.io.save(os.path.join(datapath, 'data.h5'), dfc.loc[:, compileddatacols])\n",
    "dp.io.save(os.path.join(datapath, 'descriptions.h5'), dfc.loc[:, compiledinfocols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.io.save(os.path.join(datapath, 'descriptions.h5'), dfc.loc[:, compiledinfocols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp.io.save(os.path.join(datapath, 'compiled.h5'), dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
